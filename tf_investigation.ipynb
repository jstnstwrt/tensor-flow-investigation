{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google's Tensor Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will introduce it and demonstrate some basic functionality of the library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow is a very flexible machine learning library specifically designed to do deep learning efficiently (but it can also do other types of machine learning as well). \n",
    "\n",
    "TensorFlow grew out of the Google Brain reasearch project, which is Google's research lab dedicated to developing deep learning technologies. The project is led by Google fellow Jeff Dean. TF was open sourced for the world to use and contribute to November 09, 2015.\n",
    "\n",
    "Google uses TensorFlow for speech recognition software, their Google Photos product, search, and others. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where does the name TensorFlow come from?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*\"TensorFlow (TF) is an open source software library for numerical computation using data flow graphs.\"* --https://www.tensorflow.org/\n",
    "\n",
    "A tensor is a multi-dimensional array of numbers. For example, a matrix is an example of a tensor with rank 2 (where the rank is the number of dimensions necessary to represent it).\n",
    "\n",
    "So in the context of TensorFlow, **tensors represent the data** in the machine learning algorithm. \n",
    "\n",
    "Now let's consider the concept: *data flow graphs*. \n",
    "\n",
    "In general, a graph is a set if vertices (or nodes) connected by edges. \n",
    "\n",
    "In this context, it is very powerful then to have the **nodes of the graph represent mathematical computations**.\n",
    "\n",
    "The key idea underlying TensorFlow is that we can represent certain machine learning algorithms as **directed acyclic graph**, where the data (tensors) flows through the graph along it's edges and are transformed via computations at every node.\n",
    "\n",
    "TensorFlow can be used to implement any machine learning algorithm that can be represented in this way, not just deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing a data flow graph ( a TF computation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"tensors_flowing.gif\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url='tensors_flowing.gif') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Courtesy of https://www.tensorflow.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Common Language:** TensorFlow is aiming to unify the tool kits used in research and production. The hope is that frontier machine learning techniques created by researchers and academics can be *immediately* implemented in production environments (and vice versa) *with minimal code rewrite*.\n",
    "\n",
    "\n",
    "* **Portability:** Often machine learning algorithms, like deep learning, require really really fast compute and are implemented on GPUs (or clusters) instead of CPUs. Generally, this meant that an algorithm developed on your own machine would require substantial rewrite when scaling up to these types of production environments. The TensorFlow library runs identically on all of these environments (CPU,GPU, desktop, server side, or mobile) and thus requires little to no rewrite.\n",
    "\n",
    "\n",
    "* **Flexibility:** Although TensorFlow was developed to do deep learning, it isn't just a neural networks library. The framework is flexible enough that, if an ML algorithm can be represented as a data flow graph, it can be implemented in TensorFlow.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade https://storage.googleapis.com/tensorflow/mac/tensorflow-0.6.0-py2-none-any.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need further installation information, see: https://www.tensorflow.org/versions/master/get_started/os_setup.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** You may have conflicts with your TF install and the anaconda distribution. This can be resolved through the use of virtual environments. See: https://virtualenv.readthedocs.org/en/latest/ for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: using TF for linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use Tensor Flow to fit a line to some randomly generated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use numpy to randomly generate `100` random `x`,`y` data points such that, `y = .3x + 5`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_data = np.random.rand(100).astype(\"float32\")\n",
    "y_data = .3 * x_data + 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we know the true relationship between the variables, x and y, let's  use TF to figure out the relationship from the data by fitting a line to it. That is, we will try to find values for `W` and `b` that best compute:  \n",
    "> `y_data = W * x_data + b`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first create TF variables to hold and update parameter estimates while training the model. The Variable() constructor takes a Tensor as its argument which is the variable's initial value. This value fixes the type and shape of the variable thereafter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "b = tf.Variable(tf.zeros([1]))\n",
    "y = W * x_data + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that at this point variables are not directly accessible. This is because we have not yet initislized them and launched the data flow graph. See that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.ops.variables.Variable object at 0x104f6b6d0>\n",
      "<tensorflow.python.ops.variables.Variable object at 0x104f6b650>\n",
      "Tensor(\"add_1:0\", shape=TensorShape([Dimension(100)]), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print W\n",
    "print b\n",
    "print y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we need to add the initialize operation to the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create the model (i.e., graph) using the Session constructor and use the run method to actually preform the computation that launches and initializes the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then preform operations to actually compute variables and interact with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.48991966]\n",
      "[ 0.]\n",
      "[-0.44582376 -0.20537969 -0.35519788 -0.10802381 -0.13590927 -0.09531834\n",
      " -0.28230846 -0.08044608 -0.43287539 -0.31314573 -0.13787559 -0.04427009\n",
      " -0.20626163 -0.31519145 -0.03529301 -0.45107517 -0.07701161 -0.35351011\n",
      " -0.16803266 -0.06855715 -0.35646373 -0.14249441 -0.2447892  -0.26679656\n",
      " -0.29230043 -0.38167202 -0.13759403 -0.14017805 -0.23570529 -0.21756527\n",
      " -0.01933839 -0.37756637 -0.40337226 -0.39630961 -0.31595647 -0.1790354\n",
      " -0.39419901 -0.2729308  -0.45138004 -0.4447116  -0.31842807 -0.0770814\n",
      " -0.03202143 -0.17669785 -0.14409824 -0.28185448 -0.17842738 -0.34181565\n",
      " -0.30376226 -0.33673066 -0.24293828 -0.11618464 -0.26944926 -0.06024968\n",
      " -0.46045059 -0.27578354 -0.46595353 -0.14781049 -0.41646111 -0.33339438\n",
      " -0.07441436 -0.10317279 -0.26891214 -0.32484469 -0.21951206 -0.43761945\n",
      " -0.44823289 -0.30573538 -0.01232903 -0.18518613 -0.05272623 -0.41724572\n",
      " -0.46271065 -0.2709823  -0.36794505 -0.16058531 -0.22156136 -0.18219641\n",
      " -0.3120963  -0.09502858 -0.32903379 -0.33191302 -0.03775922 -0.44692042\n",
      " -0.2086923  -0.00221374 -0.15749237 -0.20911911 -0.48103553 -0.32727095\n",
      " -0.1172189  -0.39058354 -0.03066654 -0.11896123 -0.46572822 -0.41570467\n",
      " -0.17838043 -0.31475154 -0.41566804 -0.1400378 ]\n"
     ]
    }
   ],
   "source": [
    "print sess.run(W)\n",
    "print sess.run(b)\n",
    "print sess.run(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a model to discover to the relationship between `x` and `y` created above. We use the mean squared error as a loss function and gradient descent to find the optimum. By iteratively applying gradient descent (training the model), we can learn estimates (`W` and `b`) of the true parameters (`.3` and `5`, resp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.square(y - y_data))\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we again initialize all the variables and run the session to launch the graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then iteratively train the model using `sess.run(train)` and watch as the values of `W` and `b` converge to the true parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 2.45145178] [ 5.30806303]\n",
      "10 [ 1.12799895] [ 4.55058527]\n",
      "20 [ 0.74730206] [ 4.75721502]\n",
      "30 [ 0.54164237] [ 4.86884212]\n",
      "40 [ 0.4305405] [ 4.92914581]\n",
      "50 [ 0.37052062] [ 4.96172285]\n",
      "60 [ 0.33809665] [ 4.97932196]\n",
      "70 [ 0.32058045] [ 4.98882914]\n",
      "80 [ 0.31111789] [ 4.99396563]\n",
      "90 [ 0.30600619] [ 4.99673986]\n",
      "100 [ 0.30324462] [ 4.99823904]\n",
      "110 [ 0.30175263] [ 4.99904871]\n",
      "120 [ 0.30094671] [ 4.99948597]\n",
      "130 [ 0.30051145] [ 4.99972248]\n",
      "140 [ 0.30027616] [ 4.9998498]\n",
      "150 [ 0.30014932] [ 4.99991894]\n",
      "160 [ 0.30008042] [ 4.99995613]\n",
      "170 [ 0.3000432] [ 4.99997663]\n",
      "180 [ 0.30002326] [ 4.99998713]\n",
      "190 [ 0.30001247] [ 4.99999332]\n",
      "200 [ 0.30000669] [ 4.99999619]\n"
     ]
    }
   ],
   "source": [
    "for step in xrange(201):\n",
    "    sess.run(train)\n",
    "    if step % 10 ==0:\n",
    "        print step, sess.run(W), sess.run(b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find more information and resources here: https://www.tensorflow.org/versions/master/tutorials/index.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
