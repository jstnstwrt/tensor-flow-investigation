{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google's Tensor Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will introduce and demonstrate some of the functionality of Google's Tensor Flow library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"TensorFlow (TF) is an open source software library for numerical computation using data flow graphs.\"\n",
    "\n",
    "Basically, it is a very flexible machine learning library specifically designed to do deep learning efficiently (but it can also do other types of machine learning as well). \n",
    "\n",
    "TensorFlow grew out of the Google Brain reasearch project, which is Google's research lab dedicated to developing deep learning technologies. The project is led by Google fellow Jeff Dean. TF was open sourced for the world to use and contribute to November 09, 2015.\n",
    "\n",
    "Google uses TensorFlow for speech recognition software, their Google photos product, search, and others. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where does the name TensorFlow come from?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tensor is a multi-dimensional array of numbers. For example, a matrix is an example of a tensor with rank 2 (where the rank is the number of dimensions necessary to represent it).\n",
    "\n",
    "So in the context of TensorFlow, **tensors represents the data**. \n",
    "\n",
    "Now get some further insight from considering the phrase: 'data flow graphs'. \n",
    "\n",
    "In general, a graph is a set if vertices (or nodes) connected by edges. \n",
    "\n",
    "It is very powerful in this context to have the **nodes of the graph represent mathematical computations**.\n",
    "\n",
    "The key idea underlying TensorFlow is that we can represent a machine learning algorithm as **directed acyclic graph** where data flows through the graph along it's edges and is transformed via computations at every node.\n",
    "\n",
    "TensorFlow can be used to implement any machine learning algorithm that can be represented in this way, not just deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing a data flow graph ( a TF computation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"tensors_flowing.gif\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url='tensors_flowing.gif') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Courtesy of https://www.tensorflow.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Common Language:** unify the tools used in research and production. give a common language.\n",
    "\n",
    "2. **Portability:** historically lots of this work has been designed to run on gpus and clusters and wasnt neccessarily easily available for the everyday person to run on there own machine. this makes this possible. so if you write your code on your own pc, then want to scale it up to run on a gpu (or mobile), you dont have to change your code to do so.\n",
    "\n",
    "3. **Flexibility:** \"TensorFlow isn't a rigid neural networks library. If you can express your computation as a data flow graph, you can use TensorFlow. You construct the graph, and you write the inner loop that drives computation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade https://storage.googleapis.com/tensorflow/mac/tensorflow-0.6.0-py2-none-any.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need further installation information, see: https://www.tensorflow.org/versions/master/get_started/os_setup.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A further note: you may have issue of conflicts with you TF install and the anaconda distribution or other packages you have installed. This can be resolved through the use of virtual environments. A virtual environment allows you to locally install packages into a container. Anaconda has there own version of virtual environments but the classic is virtualenv. See: https://virtualenv.readthedocs.org/en/latest/ for more details. Also note that when using jupyter notebooks with a virtual environment, that when you launch the kernel inside your directory, the virtual environment is activated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use Tensor Flow to fit a line to some randomly generated data in 2-space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use numpy to randomly generate some data for us to use. Create 100 random x,y data points such that, y = .3x + 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data = np.random.rand(100).astype(\"float32\")\n",
    "y_data = .3 * x_data + 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we know the true relationship between the variables, x and y, we can use TF to figure out the relationship from the data. That is, we will try to find values for w and b that best compute:  ```y_data = w * x_data + b``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "b = tf.Variable(tf.zeros([1]))\n",
    "y = w * x_data + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'When you train a model, you use variables to hold and update parameters. Variables are in-memory buffers containing tensors. They must be explicitly initialized and can be saved to disk during and after training. You can later restore saved values to exercise or analyse the model.' \n",
    "\n",
    "When you create a Variable you pass a Tensor as its initial value to the Variable() constructor. \n",
    "\n",
    "The Variable() constructor requires an initial value for the variable, which can be a Tensor of any type and shape. The initial value defines the type and shape of the variable. After construction, the type and shape of the variable are fixed. The value can be changed using one of the assign methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.ops.variables.Variable object at 0x109ceca10>\n",
      "<tensorflow.python.ops.variables.Variable object at 0x10a060f90>\n",
      "Tensor(\"add_4:0\", shape=TensorShape([Dimension(100)]), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print w\n",
    "print b\n",
    "print y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.36020875]\n",
      "[ 0.]\n",
      "[-0.09224915 -0.35459417 -0.03553534 -0.14892139 -0.22565894 -0.01448729\n",
      " -0.02427903 -0.01360498 -0.15798664 -0.29686695 -0.26807514 -0.31933096\n",
      " -0.31017977 -0.18296419 -0.14362891 -0.21261223 -0.14166476 -0.11143228\n",
      " -0.00717545 -0.17705578 -0.26840606 -0.00325437 -0.34626579 -0.26646021\n",
      " -0.19789295 -0.32161212 -0.07533059 -0.0278699  -0.01273447 -0.28332257\n",
      " -0.33917403 -0.0837416  -0.12137917 -0.23600952 -0.19764116 -0.24937132\n",
      " -0.11454682 -0.27082282 -0.24864112 -0.15161434 -0.33814704 -0.21708332\n",
      " -0.232144   -0.25783247 -0.15087759 -0.21762969 -0.10684363 -0.30600864\n",
      " -0.21623978 -0.22530949 -0.12519775 -0.11827576 -0.03542566 -0.00466454\n",
      " -0.16648419 -0.23630635 -0.10162813 -0.12473053 -0.04722381 -0.1273431\n",
      " -0.02915932 -0.04372462 -0.13924918 -0.29088402 -0.01894105 -0.21039066\n",
      " -0.26028156 -0.26882362 -0.01822791 -0.1635935  -0.13723204 -0.13079903\n",
      " -0.0147856  -0.10270353 -0.04246591 -0.27679849 -0.05404299 -0.13758284\n",
      " -0.29944071 -0.17853391 -0.33858305 -0.20595016 -0.21281032 -0.29867679\n",
      " -0.0108248  -0.19980252 -0.03253363 -0.10989642 -0.21949433 -0.22452098\n",
      " -0.21277893 -0.20724554 -0.35181487 -0.15765461 -0.33909234 -0.28800339\n",
      " -0.04490805 -0.21367693 -0.32098043 -0.20920748]\n"
     ]
    }
   ],
   "source": [
    "print sess.run(w)\n",
    "print sess.run(b)\n",
    "print sess.run(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimize the mean squared errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.square(y - y_data))\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting, initialize the variables.  We will 'run' this first. And then launch the graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 1.95886159] [ 5.53669071]\n",
      "20 [ 0.58591932] [ 4.85211039]\n",
      "40 [ 0.37501925] [ 4.9611969]\n",
      "60 [ 0.31968358] [ 4.98981905]\n",
      "80 [ 0.30516452] [ 4.99732876]\n",
      "100 [ 0.30135521] [ 4.99929905]\n",
      "120 [ 0.30035546] [ 4.99981594]\n",
      "140 [ 0.30009338] [ 4.99995184]\n",
      "160 [ 0.30002472] [ 4.99998713]\n",
      "180 [ 0.30000666] [ 4.99999666]\n",
      "200 [ 0.30000168] [ 4.99999905]\n"
     ]
    }
   ],
   "source": [
    "for step in xrange(201):\n",
    "    sess.run(train)\n",
    "    if step % 20 ==0:\n",
    "        print step, sess.run(w), sess.run(b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further reasources"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
